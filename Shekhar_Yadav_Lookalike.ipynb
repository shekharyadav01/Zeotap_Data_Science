{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79e561f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02681ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "products_df = pd.read_csv('Products.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0746707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Clean column names by stripping any leading/trailing spaces\n",
    "customers_df.columns = customers_df.columns.str.strip()\n",
    "products_df.columns = products_df.columns.str.strip()\n",
    "transactions_df.columns = transactions_df.columns.str.strip()\n",
    "\n",
    "# Display the first few rows of each dataset to verify the data\n",
    "print(customers_df.head())\n",
    "print(products_df.head())\n",
    "print(transactions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cc0fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in products_df: Index(['ProductID', 'ProductName', 'Category', 'Price'], dtype='object')\n",
      "Columns after merge: Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
      "       'Quantity', 'TotalValue', 'Price_x', 'ProductName', 'Category',\n",
      "       'Price_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check if the 'Category' column exists in products_df\n",
    "print(\"Columns in products_df:\", products_df.columns)\n",
    "\n",
    "# Merge transactions with product information\n",
    "transactions_df = transactions_df.merge(products_df, on='ProductID', how='left')\n",
    "\n",
    "# Check if the 'Category' column was successfully merged\n",
    "print(\"Columns after merge:\", transactions_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9deda1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID         Region SignupDate\n",
      "0      C0001  South America 2022-07-10\n",
      "1      C0002           Asia 2022-02-13\n",
      "2      C0003  South America 2024-03-07\n",
      "3      C0004  South America 2022-10-09\n",
      "4      C0005           Asia 2022-08-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shekh\\AppData\\Local\\Temp\\ipykernel_17276\\1487893007.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customer_profile['SignupDate'] = pd.to_datetime(customer_profile['SignupDate'])\n"
     ]
    }
   ],
   "source": [
    "# Prepare customer profile data (only relevant columns)\n",
    "customer_profile = customers_df[['CustomerID', 'Region', 'SignupDate']]\n",
    "\n",
    "# Convert 'SignupDate' to datetime format\n",
    "customer_profile['SignupDate'] = pd.to_datetime(customer_profile['SignupDate'])\n",
    "\n",
    "# Display the customer profile to verify the data\n",
    "print(customer_profile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d71f9e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID          0\n",
      "Region              0\n",
      "SignupDate          0\n",
      "total_spent         1\n",
      "num_transactions    1\n",
      "dtype: int64\n",
      "  CustomerID         Region SignupDate  total_spent  num_transactions\n",
      "0      C0001  South America 2022-07-10      3354.52               5.0\n",
      "1      C0002           Asia 2022-02-13      1862.74               4.0\n",
      "2      C0003  South America 2024-03-07      2725.38               4.0\n",
      "3      C0004  South America 2022-10-09      5354.88               8.0\n",
      "4      C0005           Asia 2022-08-15      2034.24               3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shekh\\AppData\\Local\\Temp\\ipykernel_17276\\1698593543.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customer_profile['total_spent'].fillna(0, inplace=True)\n",
      "C:\\Users\\shekh\\AppData\\Local\\Temp\\ipykernel_17276\\1698593543.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customer_profile['num_transactions'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate transaction data for each customer\n",
    "customer_transactions = transactions_df.groupby('CustomerID').agg(\n",
    "    total_spent=('TotalValue', 'sum'),\n",
    "    num_transactions=('TransactionID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Merge the aggregated transaction data with the customer profile\n",
    "customer_profile = customer_profile.merge(customer_transactions, on='CustomerID', how='left')\n",
    "\n",
    "# Check for missing values after merge\n",
    "print(customer_profile.isnull().sum())\n",
    "\n",
    "# Fill NaN values with 0 for 'total_spent' and 'num_transactions' if any missing\n",
    "customer_profile['total_spent'].fillna(0, inplace=True)\n",
    "customer_profile['num_transactions'].fillna(0, inplace=True)\n",
    "\n",
    "# Display the updated customer profile after filling missing values\n",
    "print(customer_profile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f40b5a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Region SignupDate  total_spent  num_transactions  signup_year\n",
      "0      C0001       3 2022-07-10      3354.52               5.0         2022\n",
      "1      C0002       0 2022-02-13      1862.74               4.0         2022\n",
      "2      C0003       3 2024-03-07      2725.38               4.0         2024\n",
      "3      C0004       3 2022-10-09      5354.88               8.0         2022\n",
      "4      C0005       0 2022-08-15      2034.24               3.0         2022\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Region' to a numerical code\n",
    "customer_profile['Region'] = customer_profile['Region'].astype('category').cat.codes\n",
    "\n",
    "# Add a 'signup_year' feature extracted from the 'SignupDate'\n",
    "customer_profile['signup_year'] = customer_profile['SignupDate'].dt.year\n",
    "\n",
    "# Display the customer profile after feature engineering\n",
    "print(customer_profile.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e124aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.24138358 -0.05188436  0.         -1.27635218]\n",
      " [-1.40925752 -0.86271433 -0.45129368 -1.27635218]\n",
      " [ 1.24138358 -0.393842   -0.45129368  1.09825653]\n",
      " [ 1.24138358  1.03537505  1.35388105 -1.27635218]\n",
      " [-1.40925752 -0.76949861 -0.90258736 -1.27635218]]\n"
     ]
    }
   ],
   "source": [
    "# Select features for similarity calculation\n",
    "features = customer_profile[['Region', 'total_spent', 'num_transactions', 'signup_year']]\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Display the normalized features\n",
    "print(features_scaled[:5])  # Display the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66e0b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(features_scaled)\n",
    "\n",
    "# Display the similarity matrix shape\n",
    "print(similarity_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2241065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C0152', 0.999954289194027), ('C0011', 0.9934625127648987), ('C0174', 0.9902719390028006)]\n"
     ]
    }
   ],
   "source": [
    "# Function to get top 3 lookalike customers based on cosine similarity\n",
    "def get_top_lookalikes(customer_id, similarity_matrix, customer_profile):\n",
    "    # Find the index of the customer_id\n",
    "    customer_index = customer_profile[customer_profile['CustomerID'] == customer_id].index[0]\n",
    "    \n",
    "    # Get the similarity scores for the customer\n",
    "    similarity_scores = similarity_matrix[customer_index]\n",
    "    \n",
    "    # Create a list of customer ids with similarity scores\n",
    "    similar_customers = []\n",
    "    for i, score in enumerate(similarity_scores):\n",
    "        if i != customer_index:  # Exclude the customer itself\n",
    "            similar_customers.append((customer_profile.iloc[i]['CustomerID'], score))\n",
    "    \n",
    "    # Sort by similarity score (highest first) and take top 3\n",
    "    similar_customers.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similar_customers[:3]\n",
    "\n",
    "# Display top 3 lookalikes for the first customer (C0001)\n",
    "top_lookalikes = get_top_lookalikes('C0001', similarity_matrix, customer_profile)\n",
    "print(top_lookalikes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c54e501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C0152', 0.999954289194027), ('C0011', 0.9934625127648987), ('C0174', 0.9902719390028006)]\n"
     ]
    }
   ],
   "source": [
    "# Generate top 3 lookalikes for the first 20 customers\n",
    "lookalikes_dict = {}\n",
    "for customer_id in customer_profile['CustomerID'][:20]:\n",
    "    lookalikes_dict[customer_id] = get_top_lookalikes(customer_id, similarity_matrix, customer_profile)\n",
    "\n",
    "# Display the lookalikes for the first customer\n",
    "print(lookalikes_dict['C0001'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da14d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID LookalikeCustomerID  SimilarityScore\n",
      "0      C0001               C0152         0.999954\n",
      "1      C0001               C0011         0.993463\n",
      "2      C0001               C0174         0.990272\n",
      "3      C0002               C0027         0.984926\n",
      "4      C0002               C0005         0.978967\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for export\n",
    "lookalike_data = []\n",
    "for customer_id, lookalikes in lookalikes_dict.items():\n",
    "    for lookalike, score in lookalikes:\n",
    "        lookalike_data.append([customer_id, lookalike, score])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'LookalikeCustomerID', 'SimilarityScore'])\n",
    "\n",
    "# Display the first few rows of the lookalike DataFrame\n",
    "print(lookalike_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d28eb26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike recommendations saved to 'Lookalike.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the lookalike results to a CSV file\n",
    "lookalike_df.to_csv('Shekhar_Yadav_Lookalike.csv', index=False)\n",
    "\n",
    "# Notify user that the CSV has been saved\n",
    "print(\"Lookalike recommendations saved to 'Lookalike.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864c342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
